import os
import yaml
from pathlib import Path
from openai import OpenAI
from datetime import datetime

# === Configuration ===
JOURNAL_DIR = Path("filing_cabinet/journals/")
TAG_FIELDS = ["tags", "summary", "emotion"]
MODEL = "gpt-4o-mini"

# === Load your API key (assumes .env or kern_secrets is configured) ===
client = OpenAI()

def get_untagged_journal_files() -> list:
    return [
        f for f in JOURNAL_DIR.glob("*.yaml")
        if not any(tag in open(f, encoding="utf-8").read() for tag in TAG_FIELDS)
    ]

def load_journal_entry(path: Path) -> dict:
    with path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def save_journal_entry(path: Path, data: dict):
    with path.open("w", encoding="utf-8") as f:
        yaml.safe_dump(data, f, sort_keys=False)

def generate_tags(entry_text: str) -> dict:
    prompt = f"""You are Kern, an emotionally aware but dry-witted assistant.
Analyze the following journal entry and return a YAML block with three fields:
- tags: 3–5 lowercase keywords
- summary: a 1–2 sentence summary of what was expressed
- emotion: the user's emotional tone in one word

Respond ONLY with valid YAML.

Journal Entry:
\"\"\"
{entry_text.strip()}
\"\"\"
"""

    response = client.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    output = response.choices[0].message.content
    try:
        return yaml.safe_load(output)
    except Exception as e:
        print(f"[ERROR] Failed to parse YAML from GPT: {e}\n---\n{output}")
        return {}

def apply_airik_compliance(generated_fields: dict, model: str = MODEL) -> dict:
    """Adds AIRIK-compliant attribution for all fields generated by Kern."""
    now = datetime.utcnow().isoformat()
    return {
        field: {
            "by": "kern",
            "model": model,
            "created": now
        } for field in generated_fields.keys()
    }

def process_all_journals(dry_run: bool = False):
    files = get_untagged_journal_files()
    print(f"[INFO] Found {len(files)} untagged journal entries.")

    for file in files:
        print(f"[→] Tagging: {file.name}")
        data = load_journal_entry(file)

        # Use either 'entry' field or fallback to entire file
        entry_text = data.get("entry") or yaml.safe_dump(data)
        tags = generate_tags(entry_text)

        if not tags:
            print(f"[!] Skipped {file.name} due to tagging error.")
            continue

        if dry_run:
            print(f"\n--- Suggested Tags for {file.name} ---\n{yaml.safe_dump(tags)}\n")
        else:
            data.update(tags)
            data["kern_generated"] = apply_airik_compliance(tags)
            save_journal_entry(file, data)
            print(f"[✓] Updated {file.name} with AIRIK-compliant tags.")

if __name__ == "__main__":
    # Run with dry_run=True to preview without writing changes
    process_all_journals(dry_run=False)
